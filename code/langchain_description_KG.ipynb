{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@zilliz_learn/vectorizing-json-data-with-milvus-for-similarity-search-1f546173162c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import GPT4AllEmbeddings, OpenAIEmbeddings\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.chains import RetrievalQA, GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import re\n",
    "import gdown\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "os.chdir('F:\\\\UNIVERSITY\\\\UNIVERSITY_DOCUMENTS\\\\DS307\\\\langchain_rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>723320</td>\n",
       "      <td>this dlc contains bonus voices for all standar...</td>\n",
       "      <td>this dlc contains bonus voices for all standar...</td>\n",
       "      <td>this dlc contains bonus voices for all standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723380</td>\n",
       "      <td>fight the wraith as you struggle to survive in...</td>\n",
       "      <td>fight the wraith as you struggle to survive in...</td>\n",
       "      <td>wraith is an action-packed horror survival gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>723420</td>\n",
       "      <td>this is a vr game about traditional chinese my...</td>\n",
       "      <td>this is a vr game about traditional chinese my...</td>\n",
       "      <td>《创世-修真录》is a vr game about traditional chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>723430</td>\n",
       "      <td>执此剑者，必仁义当先，动必有道，语必有理，求必有义，行必有正，是为君子。君子于乱世，当有执剑...</td>\n",
       "      <td>执此剑者，必仁义当先，动必有道，语必有理，求必有义，行必有正，是为君子。君子于乱世，当有执剑...</td>\n",
       "      <td>《隐龙传：影踪》众筹玩家独家武器dlc，君子之剑——斩玉剑。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>723460</td>\n",
       "      <td>the night partythey met at a midnight rave par...</td>\n",
       "      <td>the night partythey met at a midnight rave par...</td>\n",
       "      <td>the night party they met at a midnight rave pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   steam_appid                               detailed_description  \\\n",
       "0       723320  this dlc contains bonus voices for all standar...   \n",
       "1       723380  fight the wraith as you struggle to survive in...   \n",
       "2       723420  this is a vr game about traditional chinese my...   \n",
       "3       723430  执此剑者，必仁义当先，动必有道，语必有理，求必有义，行必有正，是为君子。君子于乱世，当有执剑...   \n",
       "4       723460  the night partythey met at a midnight rave par...   \n",
       "\n",
       "                                      about_the_game  \\\n",
       "0  this dlc contains bonus voices for all standar...   \n",
       "1  fight the wraith as you struggle to survive in...   \n",
       "2  this is a vr game about traditional chinese my...   \n",
       "3  执此剑者，必仁义当先，动必有道，语必有理，求必有义，行必有正，是为君子。君子于乱世，当有执剑...   \n",
       "4  the night partythey met at a midnight rave par...   \n",
       "\n",
       "                                   short_description  \n",
       "0  this dlc contains bonus voices for all standar...  \n",
       "1  wraith is an action-packed horror survival gam...  \n",
       "2  《创世-修真录》is a vr game about traditional chinese...  \n",
       "3                     《隐龙传：影踪》众筹玩家独家武器dlc，君子之剑——斩玉剑。  \n",
       "4  the night party they met at a midnight rave pa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_csv = pd.read_csv('csv/game_description_df.csv')\n",
    "db_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('csv/only_description.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EMBEDDING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer(\"intfloat/multilingual-e5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-base\", model_kwargs={\"trust_remote_code\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parent Document Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretriever.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mload_pickle\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pickle\u001b[39m(path):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 3\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py:371\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1040\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1268\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1266\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1267\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1268\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1272\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1205\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1201\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1205\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1206\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1207\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1208\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m typed_storage\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:391\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 391\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:266\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    268\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:250\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    247\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    251\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    252\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    255\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# retriever = load_pickle('retriever.pkl')\n",
    "# vectorstore = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "list_steam_appids, list_descriptions = data['steam_appid'], data['clean_description']\n",
    "for appid, description in zip(list_steam_appids[:1], list_descriptions[:1]):\n",
    "    description = str(description)\n",
    "    document = Document(\n",
    "        page_content=description,\n",
    "        # metadata= {\"id\": appid}, \n",
    "    )\n",
    "    document_dic = {\n",
    "        'page_content': document\n",
    "    }\n",
    "    docs.append(document_dic)\n",
    "    # docs.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using a corrected store implementation\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "# from langchain.vectorstores import InMemoryStore  # Ensure InMemoryStore is imported from the correct module\n",
    "# from langchain_community.docstore.base import AddableMixin\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import faiss\n",
    "\n",
    "# Initialize documents\n",
    "docs = []\n",
    "list_steam_appids, list_descriptions = data['steam_appid'], data['clean_description']\n",
    "\n",
    "# Only process a smaller subset for testing\n",
    "for appid, description in zip(list_steam_appids, list_descriptions):\n",
    "    description = str(description)\n",
    "    \n",
    "    # Create a document object\n",
    "    document = Document(\n",
    "        page_content=description,\n",
    "        metadata= {\"id\": appid}, \n",
    "    )\n",
    "    docs.append(document)\n",
    "\n",
    "# Text Splitter (using smaller chunks)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=64, chunk_overlap=32)\n",
    "\n",
    "# Ensure embedding query returns a valid dimensionality\n",
    "sample_text = 'Random World Iu Hai Quynh Nhat'\n",
    "embedding_dim = len(embeddings.embed_query(sample_text))  # Check the dimension\n",
    "\n",
    "nlist = 100  # Number of partitions in FAISS index\n",
    "# quantizer = faiss.IndexFlatL2(embedding_dim)\n",
    "# index = faiss.IndexIVFFlat(quantizer, embedding_dim, nlist)\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "# Correctly initialize the FAISS vector store\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),  # Make sure InMemoryStore implements BaseStore\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "# Create the ParentDocumentRetriever with the correct parameters\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    # docstore=store,\n",
    "    byte_store=store,\n",
    "    child_splitter=child_splitter,\n",
    ")\n",
    "\n",
    "# Add documents to the retriever\n",
    "retriever.add_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vector store\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "# vectorstore = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 723420, 'doc_id': 'e84efa3c-ed17-456f-84a5-c4f50b1a6bb5'}, page_content='mythology. game act theurgy practicer train fighting evil force'),\n",
       " Document(metadata={'id': 723380, 'doc_id': '83e5d221-99cd-4f55-851e-c821c89e3a0d'}, page_content='watch crawl ground kill overall increase health game'),\n",
       " Document(metadata={'id': 723420, 'doc_id': 'e84efa3c-ed17-456f-84a5-c4f50b1a6bb5'}, page_content='story mode play. go ahead pick sword fight evil'),\n",
       " Document(metadata={'id': 723320, 'doc_id': 'c6934031-e9d1-47de-b293-ea333bd6ea74'}, page_content='f levinasshinobu sanjophilomena pasquinitheo tveitgustav')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"Horror film\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Text Splitter (splitting into chunks of 400 characters)\n",
    "# child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "# # Example embedding model\n",
    "# d = len(model.encode('Random World Iu Hai Quynh Nhat'))  # Get the dimensionality of the embeddings\n",
    "\n",
    "# # Initialize the FAISS index\n",
    "# nlist = 100  # Number of clusters\n",
    "# quantizer = faiss.IndexFlatL2(d)  # Use flat index as quantizer\n",
    "# index = faiss.IndexIVFFlat(quantizer, d, nlist)  # Inverted file index\n",
    "\n",
    "# # Define the FAISS vector store\n",
    "# vectorstore = FAISS(\n",
    "#     embedding_function=model,  # Your embedding function\n",
    "#     index=index,\n",
    "#     docstore=InMemoryDocstore(),  # Store the documents in memory\n",
    "#     index_to_docstore_id={},\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# # Assuming `docs` is a list of strings (documents)\n",
    "# # docs = [\"Document 1 content\", \"Document 2 content\", \"Document 3 content\"]  # Example list of documents\n",
    "\n",
    "# # Initialize the ParentDocumentRetriever\n",
    "# retriever = ParentDocumentRetriever(\n",
    "#     vectorstore=vectorstore,\n",
    "#     docstore=store,\n",
    "#     child_splitter=child_splitter,\n",
    "# )\n",
    "\n",
    "# # Add documents to the retriever\n",
    "# retriever.add_documents(docs\n",
    "# , ids=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
